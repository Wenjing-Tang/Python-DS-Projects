{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Manipulation with Pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'Summer Olympic medallists 1896 to 2008 - EDITIONS.tsv'\n",
    "editions = pd.read_csv(file_path, sep='\\t')\n",
    "editions = editions[['Edition', 'Grand Total', 'City', 'Country']]\n",
    "\n",
    "ioc_codes = pd.read_csv(file_path)\n",
    "ioc_codes = ioc_codes[[\"Country\", \"NOC\"]]\n",
    "\n",
    "# Create empty dictionary: medals_dict\n",
    "medals_dict = {}\n",
    "\n",
    "for year in editions['Edition']:\n",
    "    file_path = 'summer_{:d}.csv'.format(year)\n",
    "    medals_dict[year] = pd.read_csv(file_path)\n",
    "    medals_dict[year] = medals_dict[year][['Athlete','NOC', 'Medal']]\n",
    "    medals_dict[year]['Edition'] = year\n",
    "    \n",
    "# Concatenate medals_dict: medals\n",
    "medals = pd.concat(medals_dict, ignore_index=True)\n",
    "\n",
    "# Construct the pivot_table: medal_counts\n",
    "medal_counts = medals.pivot_table(index = \"Edition\", values=\"Athlete\", columns = \"NOC\", aggfunc=\"count\")\n",
    "\n",
    "# Set Index of editions: totals\n",
    "totals = editions.set_index(\"Edition\")\n",
    "totals = totals['Grand Total']\n",
    "fractions = medal_counts.divide(totals, axis = \"rows\")\n",
    "\n",
    "# Left join editions and ioc_codes: hosts\n",
    "hosts = pd.merge(editions, ioc_codes, how = \"left\", on = \"Country\")\n",
    "\n",
    "# Extract relevant columns and set index: hosts\n",
    "hosts = hosts[[\"Edition\", \"NOC\"]].set_index(\"Edition\")\n",
    "\n",
    "# Fix missing 'NOC' values of hosts\n",
    "print(hosts.loc[hosts.NOC.isnull()])\n",
    "hosts.loc[1972, 'NOC'] = 'FRG'\n",
    "hosts.loc[1980, 'NOC'] = 'URS'\n",
    "hosts.loc[1988, 'NOC'] = 'KOR'\n",
    "\n",
    "hosts = hosts.reset_index()\n",
    "reshaped = pd.melt(fractions_change, id_vars='Edition', value_name='Change')\n",
    "print(reshaped.shape, fractions_change.shape)\n",
    "chn = reshaped[reshaped[\"NOC\"] == 'CHN']\n",
    "merged = pd.merge(reshaped, hosts, how = \"inner\")\n",
    "influence = merged.set_index(\"Edition\").sort_index()\n",
    "\n",
    "print(influence.head())\n",
    "\n",
    "# Import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "change = influence[\"Change\"]\n",
    "ax = change.plot(kind =\"bar\")\n",
    "\n",
    "# Customize the plot to improve readability\n",
    "ax.set_ylabel(\"% Change of Host Country Medal Count\")\n",
    "ax.set_title(\"Is there a Host Country Advantage?\")\n",
    "ax.set_xticklabels(editions['City'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intermediate Importing Data in Python\n",
    "\n",
    "**Import Data From Web**\n",
    "## 1. Using request\n",
    "# Method 1 \n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())\n",
    "\n",
    "# Method 2\n",
    "from urllib.request import urlopen, Request\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "request = Request(url)\n",
    "response = urlopen(request)\n",
    "print(type(response))\n",
    "response.close()\n",
    "\n",
    "## 2. Using BeautifulSoup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.python.org/~guido/'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "pretty_soup = soup.prettify()\n",
    "print(pretty_soup)\n",
    "\n",
    "## 3. Using BeautifulSoup to get text\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.python.org/~guido/'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "guido_title = soup.title\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "print(guido_text)\n",
    "\n",
    "\n",
    "**API**\n",
    "# Assign URL to variable: url\n",
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "r = requests.get(url)\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract\n",
    "pizza_extract = json_data['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)\n",
    "\n",
    "**Twitter**\n",
    "# Import package\n",
    "import tweepy, json\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables\n",
    "access_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\n",
    "access_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n",
    "consumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\n",
    "consumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions \n",
    "\n",
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Raise a ValueError if col_name is NOT in DataFrame\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError ('The DataFrame does not have a ' + col_name + ' column.')\n",
    "\n",
    "    cols_count = {}   \n",
    "    col = df[col_name]\n",
    "    \n",
    "    for entry in col:\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "       \n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Print result1\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python Data Science Toolbox\n",
    "\n",
    "zipped_lists = zip(feature_names, row_vals)\n",
    "rs_dict = dict(zipped_lists)\n",
    "\n",
    "def lists2dict(list1, list2):\n",
    "    zipped_lists = zip(list1, list2)\n",
    "    rs_dict = dict(zipped_lists)\n",
    "    return rs_dict\n",
    "\n",
    "rs_fxn = lists2dict(feature_names, row_vals)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "print(df.head())\n",
    "\n",
    "def read_large_file(file_object):\n",
    "    while True:\n",
    "        data = file_object.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n",
    "        \n",
    "with open('world_dev_ind.csv') as file:\n",
    "    gen_file = read_large_file(file)\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    \n",
    "counts_dict = {}\n",
    "\n",
    "with open('world_dev_ind.csv') as file:\n",
    "    for line in read_large_file(file):\n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1        \n",
    "print(counts_dict)\n",
    "\n",
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize = 1000)\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "print(df_urb_pop.head())\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "# Zip DataFrame columns of interest: pops\n",
    "pops = zip(df_pop_ceb['Total Population'], df_pop_ceb['Urban population (% of total)'])\n",
    "pops_list = list(pops)\n",
    "print(pops_list)\n",
    "\n",
    "# Code from previous exercise\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "pops = zip(df_pop_ceb['Total Population'], \n",
    "           df_pop_ceb['Urban population (% of total)'])\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list ]\n",
    "\n",
    "# Plot urban population data\n",
    "df_pop_ceb.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()\n",
    "\n",
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "# Initialize empty DataFrame: data\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each DataFrame chunk\n",
    "for df_urb_pop in urb_pop_reader:\n",
    "    df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "    pops = zip(df_pop_ceb['Total Population'],\n",
    "                df_pop_ceb['Urban population (% of total)'])\n",
    "    pops_list = list(pops)\n",
    "    df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "    data = data.append(df_pop_ceb)\n",
    "\n",
    "# Plot urban population data\n",
    "data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "plt.show()\n",
    "\n",
    "def plot_pop(filename, country_code):\n",
    "\n",
    "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for df_urb_pop in urb_pop_reader:\n",
    "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
    "        pops = zip(df_pop_ceb['Total Population'],\n",
    "                    df_pop_ceb['Urban population (% of total)'])\n",
    "        pops_list = list(pops)\n",
    "\n",
    "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "        data = data.append(df_pop_ceb)\n",
    "        \n",
    "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "    plt.show()\n",
    "\n",
    "# Set the filename: fn\n",
    "fn = 'ind_pop_data.csv'\n",
    "plot_pop(fn, 'CEB')\n",
    "plot_pop(fn, 'ARB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
